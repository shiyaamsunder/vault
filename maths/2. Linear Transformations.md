
# Intro

Consider a function $T$ with domain $V$ and a codomain $W$ is denoted by 

$$ T: V \rightarrow W $$

**Definition**: Let $V$ and $W$ be vector spaces (over $F$). We call a function $T: V \rightarrow W$ a linear transformation from V to W if, for all $x, y \in V$ and $c \in F$, we have

1. $T(x+y) = T(x) + T(y)$ and
2. $T(cx) = cT(x)$.

If the underlying field $F$ is a field rational numbers, then (1.) implies (2.), but in general both  (1.) and (2.) are logically independent.

We often simply call $T$ is linear. We should verify the following properties of a function $T: V \rightarrow W$

1. If $T$ is linear, then $T(0) =0$.
2. If $T$ is linear if and only if $T(cx +y) = cT(x) + T(y)$ for all $x, y \in V$ and $c \in F$.
3. If $T$ is linear, then $T(x-y) =T(x) - T(y)$ for all $x, y \in V$.
4. If $T$ is linear, if and only if $x_1,  x_2, x_3, ..., x_n \in V$ and $a_1, a_2, a_3, ...., a_n \in F$, we have $$ T (\sum_{i=1}^ {n} a_ix_i) = \sum_{i=1}^{n}a_i T(x_i)$$

Property 2 is generally used to prove that a given transformation is linear.


# Common linear transformations

![[Pasted image 20230107154618.png]]

## Rotation
For any angle $\theta$, we define $T_\theta: R^2 \rightarrow R^2$ by the rule: $T_\theta (a1,a2)$ is the vector obtained by rotating $(a1, a2)$ counterclockwise by $\theta$ if $(a1, a2) \not= (0, 0)$, and $T_\theta(0, 0) = (0, 0)$. Then $T_\theta: R^2 \rightarrow R^2$ is a linear transformation called the **rotation by $\theta$**.

## Reflection
Define $T: R^2 \rightarrow R^2$ by $T(a_1, a_2)=(a_1, âˆ’a_2)$. 
T is called the **reflection** about the x -axis.

## Projection
Define $T: R_2 \rightarrow R_2$ by $T(a_1, a_2)=(a_1, 0)$. T is called the projection on the *x-axis*

## Identity Transformation
For vector spaces $V$ and $W$ over a field $F$ we define Identity Transformation $I_V: V \rightarrow V$ by $I_V(x) = x$ for all $x \in V$. 

## Zero Transformation
For vector spaces $V$ and $W$ over a field $F$ we define Zero Transformation $T_0: V \rightarrow W$ by $T_0(x) = 0$ for all $x \in V$. 


# Null Space and Range

**Definitions**: Let $V$ and $W$ be two vectorspaces and let $T: V \rightarrow W$ be linear. 

### Null space
We define **null space** (or **kernel**) $N(T)$ of $T$ to be the set all the vectors $x$ in $V$ that map to $0$ in $W$. i.e. 

$$N(T) = \{ x \in V: T(x) = 0 \}$$

![[Linear Transformations 2023-01-08 09.31.59.excalidraw|400|center]]

Here $a_1, a_2, a_3 \in V$ maps to $0$ in W. Hence $a_1, a_2, a_3$ is a null space of T.

### Range
**Range** (or **image**) $R(T)$ of $T$ is defined as the subset of $W$ consisting of all images (under T) of vectors in V; that is **range** of T is the elements in $W$ that are obtained after applying the linear Transformation $T$.

For example $T: V \rightarrow W$ by $T(x) = x^2$ then

![[Linear Transformations 2023-01-08 10.36.55.excalidraw|400|center]]

Here the elements in W that are mapped from V is the range of T. Sometimes $R(T)$ can be the domain itself.


#theorem_2_1

# Theorom 2.1

